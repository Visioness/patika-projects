{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"diabetes.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Glucose\"].value_counts()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy = df.copy()\n",
    "df_copy[[\"Glucose\",\"BloodPressure\",\"SkinThickness\",\"Insulin\",\"BMI\"]] = df[[\"Glucose\",\"BloodPressure\",\"SkinThickness\",\"Insulin\",\"BMI\"]].replace(0,np.NaN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy.isnull().sum().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.hist(figsize=(20,20));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy[\"Glucose\"].fillna(df_copy[\"Glucose\"].mean(),inplace=True)\n",
    "df_copy[\"BloodPressure\"].fillna(df_copy[\"BloodPressure\"].mean(),inplace=True)\n",
    "df_copy[\"SkinThickness\"].fillna(df_copy[\"SkinThickness\"].median(),inplace=True)\n",
    "df_copy[\"Insulin\"].fillna(df_copy[\"Insulin\"].median(),inplace=True)\n",
    "df_copy[\"BMI\"].fillna(df_copy[\"BMI\"].mean(),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy.isnull().sum().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_copy.drop(\"Outcome\",axis=1)\n",
    "y = df_copy[\"Outcome\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "ss = StandardScaler()\n",
    "X_scaler = ss.fit_transform(X)\n",
    "df_X = pd.DataFrame(X_scaler,columns=['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin',\n",
    "       'BMI', 'DiabetesPedigreeFunction', 'Age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X_scaler,y,test_size=0.3,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src = \"knn2.png\" style=\"widht:400px;height:300px\" ><center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K- Nearest Neighbors(K-En Yakın Komşu) algoritması, vakaları diğer vakalarla benzerliklerine göre sınıflandırır. \"Aynı sınıf etiketlerine sahip benzer durumlar birbirine yakındır\" düşüncesini benimser. İki nokta arasındaki mesafe farklılığın bir ölçüsüdür.\n",
    "\n",
    "Algoritma adımları şöyle ilerler: \n",
    "\n",
    "1- K için bir değer seçin.\n",
    "\n",
    "2- Veri kümesindeki vakaların her birinden yeni durumdan uzaklığı hesaplayın. \n",
    "\n",
    "<center><img src = \"öklid.png\" style=\"widht:400px;height:300px\" ><center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3- Bilinmeyen veri noktasının ölçümlerine en yakın olan eğitim verilerindeki K-gözlemlerini arayın.\n",
    "\n",
    "4- En Yakın Komşulardan gelen en popüler yanıt değerini kullanarak bilinmeyen veri noktasının yanıtını tahmin edin."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src = \"knn.png\" style=\"widht:400px;height:300px\" ><center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performans Değerlendirme Metrikleri\n",
    "\n",
    "### Confusion Matrix\n",
    "\n",
    "Bir sınıflandırma modelinin performansını değerlendirmek için kullanılan bir tablodur. İki sınıf (gerçek ve tahmin edilen) ve bu sınıflara ait doğru ve yanlış sınıflandırılan örnekleri gösterir. Karmaşıklık matrisi dört temel terimden oluşur:\n",
    "\n",
    "True Positive (TP): Gerçek pozitif, doğru olarak pozitif olarak tahmin edilen örnekler.\n",
    "\n",
    "True Negative (TN): Gerçek negatif, doğru olarak negatif olarak tahmin edilen örnekler.\n",
    "\n",
    "False Positive (FP): Yanlış pozitif, yanlış olarak pozitif olarak tahmin edilen örnekler.\n",
    "\n",
    "False Negative (FN): Yanlış negatif, yanlış olarak negatif olarak tahmin edilen örnekler.\n",
    "\n",
    "<center><img src = \"cf.png\" style=\"widht:400px;height:300px\" ><center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy\n",
    "\n",
    "Accuracy, bir sınıflandırma modelinin doğru tahminlerinin tüm tahminlere oranını temsil eden bir performans ölçüsüdür. Basit bir şekilde, doğru sınıflandırılmış örneklerin toplam örnek sayısına bölünmesiyle elde edilir.\n",
    "\n",
    "<center><img src = \"accuracy.png\" style=\"widht:200px;height:100px\" ><center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recall (Duyarlılık)\n",
    "\n",
    "Bu metrik, bir sınıfın ne kadar iyi tespit edildiğini gösterir. Yani, gerçek pozitiflerin, gerçek pozitiflerle yanlış negatiflerin toplamına oranıdır. Recall, kaç tane gerçek pozitif örneğinin doğru bir şekilde tespit edildiğini belirtir. Yüksek recall değeri, modelin olumlu örnekleri kaçırmama yeteneğini gösterir.\n",
    "\n",
    "<center><img src = \"recall.png\" style=\"widht:200px;height:100px\" ><center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision (Hassasiyet)\n",
    "\n",
    "Bu metrik, bir sınıfın ne kadar doğru tahmin edildiğini gösterir. Yani, doğru pozitiflerin, doğru pozitiflerle yanlış pozitiflerin toplamına oranıdır. Precision, pozitif olarak tahmin edilen örneklerin ne kadarının gerçekten pozitif olduğunu gösterir. Yüksek precision değeri, modelin pozitif tahminlerinin doğruluğunu gösterir.\n",
    "\n",
    "<center><img src = \"precision.png\" style=\"widht:100px;height:100px\" ><center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F1 Score\n",
    "\n",
    "Precision ve recall'ın harmonik ortalamasıdır. F1-score, bir sınıflandırıcı modelin kesinliği ve kapsamlılığı arasındaki dengeyi sağlayarak bir performans ölçüsü sağlar.\n",
    "\n",
    "<center><img src = \"f1score.png\" style=\"widht:100px;height:100px\" ><center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_model = knn.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = knn_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "print(\"Classification Report is:\\n\",classification_report(y_test,y_pred))\n",
    "print(\"\\n F1:\\n\",f1_score(y_test,y_pred))\n",
    "print(\"\\n Precision score is:\\n\",precision_score(y_test,y_pred))\n",
    "print(\"\\n Recall score is:\\n\",recall_score(y_test,y_pred))\n",
    "print(\"\\n Confusion Matrix:\\n\")\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "plt.figure(figsize=(15,8))\n",
    "sns.heatmap(confusion_matrix(y_test,y_pred),annot=True)\n",
    "plt.ylabel('Prediction',fontsize=13)\n",
    "plt.xlabel('Actual',fontsize=13)\n",
    "plt.title('Confusion Matrix',fontsize=17)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_scores = []\n",
    "train_scores = []\n",
    "\n",
    "for i in range(1,15):\n",
    "\n",
    "    knn = KNeighborsClassifier(i)\n",
    "    knn.fit(X_train,y_train)\n",
    "    \n",
    "    train_scores.append(knn.score(X_train,y_train))\n",
    "    test_scores.append(knn.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_train_score = max(train_scores)\n",
    "train_scores_ind = [i for i, v in enumerate(train_scores) if v == max_train_score]\n",
    "print('Max train score {} % and k = {}'.format(max_train_score*100,list(map(lambda x: x+1, train_scores_ind))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_test_score = max(test_scores)\n",
    "test_scores_ind = [i for i, v in enumerate(test_scores) if v == max_test_score]\n",
    "print('Max test score {} % and k = {}'.format(max_test_score*100,list(map(lambda x: x+1, test_scores_ind))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,5))\n",
    "p = sns.lineplot(range(1,15),train_scores,marker='*',label='Train Score')\n",
    "p = sns.lineplot(range(1,15),test_scores,marker='o',label='Test Score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine\n",
    "\n",
    "<center><img src=\"svm.jpg\" alt=\"Drawing\"/><center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Destek Vektör Makinesi, bir ayırıcı bularak vakaları sınıflandırabilen denetimli bir algoritmadır. Veriler lineer olarak ayrılmadığı durumlarda yüksek boyutlu bir ortamda, bir ayırıcının hiper düzlem olarak çizilebileceği şekilde dönüştürülmelidir. Veriler daha yüksek boyutlu bir alana aktarılabilir ve iki kategori arasındaki sınır bir hiper düzlem ile tanımlanabilir. \n",
    "\n",
    "Yapılan bu işleme yani, verileri, doğrusal olarak ayrılmaz bir veri kümesini doğrusal olarak ayrılabilir bir veri kümesine dönüştürebilecek şekilde daha yüksek boyutlu bir alana eşlemeye **kernelling** denir.\n",
    "\n",
    "\n",
    "<center><table><tr>\n",
    "<td> <img src=\"kernel.jpg\" alt=\"Drawing\" style=\"width: 600px;\"/> </td>\n",
    "<td> <img src=\"kernel_2.png\" alt=\"Drawing\" style=\"width: 600px;\"/> </td>\n",
    "</tr></table><center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "svm_model = SVC(kernel=\"linear\").fit(X_train,y_train)\n",
    "y_pred = svm_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm= SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_params = {\"C\": np.arange(1,10),\n",
    "              \"gamma\":(0.001, 0.01, 0.1),\n",
    "              \"kernel\":[\"linear\",\"rbf\"]}\n",
    "\n",
    "#C parametresi, SVM'in sınıflandırma hatasını nasıl kabul edeceğini belirler. C değeri ne kadar büyükse, SVM sınıflandırma hatasını azaltmak için daha fazla çaba harcar. \n",
    "#Gamma'nın değeri ne kadar büyükse, tek bir eğitim örneği, modeldeki diğer örneklerin sınıflandırılmasında daha fazla ağırlığa sahip olur. Bu da modelin eğitim verilerine aşırı uyum yapmasına neden olabilir.\n",
    "#Kernel parametresi, SVM'de kullanılan çekirdek fonksiyonunu belirler. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "svm_cv = GridSearchCV(svm,svm_params,n_jobs=-1, cv=5, verbose=1, scoring=\"accuracy\")\n",
    "\n",
    "#scoring: Modellerin performansını değerlendirmek için kullanılan bir ölçütü belirtir.\n",
    "#cv: Modellerin performansını değerlendirmek için kullanılan bir ölçütü belirtir.\n",
    "#verbose: Çıktının detay seviyesini belirtir. Ne kadar fazla ayrıntı görmek istediğinizi belirleyebilirsiniz\n",
    "#n_jobs: İşlemci çekirdeklerinin sayısını belirtir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_cv.fit(X_train, y_train)\n",
    "best_params = svm_cv.best_params_\n",
    "print(f\"Best params: {best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_tuned = SVC(C=8,gamma=0.001,kernel='linear').fit(X_train,y_train)\n",
    "y_pred_tuned = svm_tuned.predict(X_test)\n",
    "accuracy_score(y_test,y_pred_tuned)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "print(\"Classification Report is:\\n\",classification_report(y_test,y_pred_tuned))\n",
    "print(\"\\n F1:\\n\",f1_score(y_test,y_pred_tuned))\n",
    "print(\"\\n Precision score is:\\n\",precision_score(y_test,y_pred_tuned))\n",
    "print(\"\\n Recall score is:\\n\",recall_score(y_test,y_pred_tuned))\n",
    "print(\"\\n Confusion Matrix:\\n\")\n",
    "print(confusion_matrix(y_test,y_pred_tuned))\n",
    "plt.figure(figsize=(15,8))\n",
    "sns.heatmap(confusion_matrix(y_test,y_pred_tuned),annot=True)\n",
    "plt.ylabel('Prediction',fontsize=13)\n",
    "plt.xlabel('Actual',fontsize=13)\n",
    "plt.title('Confusion Matrix',fontsize=17)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree\n",
    "\n",
    "<center><img src=\"dc.png\" style=\"widht:500px;height:400px\"/><center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Karar ağaçları, veri tabanlı karar yapısını anlamak için ağaç benzeri bir model oluşturur. Bu ağaç, veri kümesini sınıflandırmak veya regresyon yapmak için bir dizi karar kuralı ve özellik içerir. Temel olarak, bir karar ağacı veri kümesindeki her bir özelliğin en iyi ayrım noktasını bulmaya çalışır ve bu ayrım noktaları kullanarak veriyi sınıflandırır veya tahmin eder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"şema.png\" style=\"widht:500px;height:400px\"/><center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eğitim veri setinin kategorileri içeren **düğümlere(nodes)** bölünmesiyle oluşur. Karar ağaçları bir özniteliği test eder ve testin sonucuna göre durumları dallandırır. Her **iç düğüm(internal node)** bir teste karşılık gelir ve her **dal(branch)** testin sonucuna karşılık gelir ve her **yaprak düğümü(leaf node)** bir hastayı bir sınıfa atar.\n",
    "\n",
    "<center><table><tr>\n",
    "<td> <img src=\"tree.png\" alt=\"Drawing\" style=\"widht:200px;height: 300px;\"/> </td>\n",
    "<td> <img src=\"tree_2.png\" alt=\"Drawing\" style=\"widht:200px;height: 300px;\"/> </td>\n",
    "<td> <img src=\"tree_3.jpg\" alt=\"Drawing\" style=\"widht:300px;height: 400px;\"/> </td>\n",
    "</tr></table><center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bir karar ağacı şöyle oluşturulur:\n",
    "\n",
    "1 - Veri kümenizden bir öznitelik seçin\n",
    "\n",
    "2 - Verilerin bölünmesinde özniteliğin önemini hesaplayın\n",
    "\n",
    "3 - Verileri en iyi özniteliğin değerine göre bölün\n",
    "\n",
    "4 - Birinci adıma geçin\n",
    "\n",
    "Algoritma, verileri bölmek için en öngörücü özelliği(feature) seçer. Bir karar ağacı oluştururken önemli olan, özelliğe göre verileri bölmek için hangi özelliğin en iyi veya daha öngörücü olduğunu belirlemektir. Karar ağaçlarının dallanacağı feature'lar entropiye göre belirlenir. \n",
    "\n",
    "<center><img src=\"entropy.png\" style=\"widht:400px;height:300px\"/><center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "tree = DecisionTreeClassifier(random_state=42).fit(X_train, y_train)\n",
    "y_pred = tree.predict(X_test)\n",
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\"criterion\": (\"entropy\",\"gini\"), #Karar ağacının düğümlerini bölmek için kullanılacak ölçütü belirler. Sıklıkla kullanılan kriterler arasında \"gini\" ve \"entropy\" bulunur. \n",
    "          \"splitter\":(\"best\", \"random\"), #Karar ağacının düğümlerini bölme stratejisini belirler.\n",
    "          \"max_depth\":(list(range(1, 10))), #Oluşturulacak olan ağacın maksimum derinliğini belirler. Bu parametre, ağacın aşırı öğrenme veya ezberleme sorunlarından kaçınmak için kullanılır. \n",
    "          \"min_samples_split\":[2, 3, 4], #Bir düğümün bölünmesi için gereken minimum örnek sayısını belirler.\n",
    "          \"min_samples_leaf\":list(range(1, 10)) #Bir yaprak düğümü oluşturmak için gerekli olan minimum örnek sayısını belirler.\n",
    "          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_clf = DecisionTreeClassifier(random_state=42)\n",
    "tree_cv = GridSearchCV(tree_clf, params, scoring=\"accuracy\", n_jobs=-1, verbose=1, cv=5)\n",
    "tree_cv.fit(X_train, y_train)\n",
    "best_params = tree_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_tuned = DecisionTreeClassifier(**best_params)\n",
    "tree_tuned.fit(X_train,y_train)\n",
    "y_pred = tree_tuned.predict(X_test)\n",
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "print(\"Classification Report is:\\n\",classification_report(y_test,y_pred))\n",
    "print(\"\\n F1:\\n\",f1_score(y_test,y_pred))\n",
    "print(\"\\n Precision score is:\\n\",precision_score(y_test,y_pred))\n",
    "print(\"\\n Recall score is:\\n\",recall_score(y_test,y_pred))\n",
    "print(\"\\n Confusion Matrix:\\n\")\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "plt.figure(figsize=(15,8))\n",
    "sns.heatmap(confusion_matrix(y_test,y_pred),annot=True)\n",
    "plt.ylabel('Prediction',fontsize=13)\n",
    "plt.xlabel('Actual',fontsize=13)\n",
    "plt.title('Confusion Matrix',fontsize=17)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest\n",
    "\n",
    "Random Forest (Rastgele ormanlar), birden fazla karar ağacının bir araya gelmesiyle oluşturulan bir topluluk öğrenme modelidir. Bu ağaçlar rastgele örneklemeler ve özelliklerin bir alt kümesi kullanılarak oluşturulur. Rastgele ormanlar, her bir ağacın tahminini alarak bu tahminlerin ortalamasını veya modunu alarak son tahmini verir. Rastgele ormanlar genellikle aşırı öğrenmeye daha dirençlidir, daha yüksek doğruluk sağlayabilir ve genellikle daha karmaşık veri setleri üzerinde daha iyi performans gösterebilir.\n",
    "\n",
    "<center><img src=\"random_forest.png\" style=\"widht:500px;height:400px\"/><center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_clf = RandomForestClassifier(n_estimators=1000, random_state=42)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "y_pred = rf_clf.predict(X_test)\n",
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = [500, 900, 1100, 1500] #Oluşturulacak olan karar ağacı sayısını belirler\n",
    "max_features = ['auto', 'sqrt'] #Her bir karar ağacında değerlendirilecek olan maksimum özellik sayısını belirler. Bu, her bir bölünmede göz önünde bulundurulacak özelliklerin sayısını kontrol eder.\n",
    "max_depth = [2, 3, 5, 10, 15, None]  #Her bir karar ağacının maksimum derinliğini belirler\n",
    "min_samples_split = [2, 5, 10]\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "\n",
    "params_grid = {\n",
    "    'n_estimators': n_estimators, \n",
    "    'max_features': max_features,\n",
    "    'max_depth': max_depth, \n",
    "    'min_samples_split': min_samples_split,\n",
    "    'min_samples_leaf': min_samples_leaf\n",
    "              }\n",
    "\n",
    "rf_clf = RandomForestClassifier(random_state=42)\n",
    "rf_cv = GridSearchCV(rf_clf, params_grid, scoring=\"accuracy\", cv=5, verbose=1, n_jobs=-1)\n",
    "rf_cv.fit(X_train, y_train)\n",
    "best_params = rf_cv.best_params_\n",
    "print(f\"Best parameters: {best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest_tuned = RandomForestClassifier(**best_params)\n",
    "random_forest_tuned.fit(X_train,y_train)\n",
    "y_pred = random_forest_tuned.predict(X_test)\n",
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "print(\"Classification Report is:\\n\",classification_report(y_test,y_pred))\n",
    "print(\"\\n F1:\\n\",f1_score(y_test,y_pred))\n",
    "print(\"\\n Precision score is:\\n\",precision_score(y_test,y_pred))\n",
    "print(\"\\n Recall score is:\\n\",recall_score(y_test,y_pred))\n",
    "print(\"\\n Confusion Matrix:\\n\")\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "plt.figure(figsize=(15,8))\n",
    "sns.heatmap(confusion_matrix(y_test,y_pred),annot=True)\n",
    "plt.ylabel('Prediction',fontsize=13)\n",
    "plt.xlabel('Actual',fontsize=13)\n",
    "plt.title('Confusion Matrix',fontsize=17)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**K-Nearest Neighbours (K-NN):** K-NN, veri kümesindeki benzer örneklerin birbirine yakın olma eğilimi varsa ve sınıflar arasındaki sınırlar belirgin değilse kullanışlı olabilir. Veri seti küçük veya orta ölçekli olduğunda etkilidir. Ayrıca, veri seti üzerindeki gürültüye ve etiketlenmemiş verilere karşı da oldukça dirençlidir.\n",
    "\n",
    "**Support Vector Machine (SVM):** SVM, yüksek boyutlu veri setleriyle çalışırken etkilidir. Veri seti arasındaki karmaşık ilişkileri anlamak ve sınıflar arasındaki net ayrımı çizmek için kullanılabilir. SVM, özellikle veri setindeki sınıf dengesizliği durumunda da etkili olabilir.\n",
    "\n",
    "**Decision Tree (Karar Ağacı):** Karar ağaçları, veri seti içindeki ilişkileri ve karar yapısını anlamak istediğinizde faydalı olabilir. Karar ağaçları anlaşılması kolaydır ve yorumlanabilirliği yüksektir. Ayrıca, kategorik ve sayısal veri türlerini işlemek için de uygundur.\n",
    "\n",
    "**Random Forest:** Random forest, karmaşık ilişkiler içeren büyük veri setleri üzerinde yüksek performans sağlar. Aynı zamanda aşırı öğrenmeye karşı dirençlidir ve genellikle daha yüksek doğruluk sağlar. Veri setindeki gürültüye ve eksik verilere karşı da oldukça dirençlidir.\n",
    "\n",
    "Bu algoritmaların seçimi, veri setinin özelliklerine, boyutuna, sınıf dengesine ve problemin doğasına bağlıdır. Veri analizi, model performansı ve doğruluk gereksinimleri gibi faktörler de seçimde rol oynar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
